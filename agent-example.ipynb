{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Retrieval Pipeline \u2014 Azure AI Search + Foundry Agent Service\n",
    "\n",
    "This notebook creates an end-to-end agentic retrieval pipeline that integrates **Azure AI Search** with **Foundry Agent Service**.\n",
    "\n",
    "Based on the [official tutorial](https://learn.microsoft.com/azure/search/agentic-retrieval-how-to-create-pipeline), with **added error handling and validation** at each step.\n",
    "\n",
    "## Steps\n",
    "1. Load connections\n",
    "2. Create a search index\n",
    "3. Upload documents to the index\n",
    "4. Create a knowledge source\n",
    "5. Create a knowledge base\n",
    "6. Set up a project client\n",
    "7. Create a project connection\n",
    "8. Create an agent with the MCP tool\n",
    "9. Chat with the agent\n",
    "10. Clean up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, make sure you have:\n",
    "\n",
    "1. Completed `sample.env` \u2192 `.env` with your Azure resource values.\n",
    "2. Run `az login` in your terminal.\n",
    "3. Assigned **all** required RBAC roles (see README.md).\n",
    "4. Enabled **system-assigned managed identity** on both Search and Foundry project.\n",
    "5. Deployed `text-embedding-3-large` and `gpt-4.1-mini` (or your chosen models) in your Foundry project.\n",
    "6. Verified that your AI Hub has associated ML resources in the Azure Portal \u2192 Resource Visualizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 \u2014 Load connections"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.core.tools import parse_resource_id\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# \u2500\u2500 Required environment variables \u2500\u2500\n",
    "required_vars = [\n",
    "    \"AZURE_SEARCH_ENDPOINT\",\n",
    "    \"PROJECT_ENDPOINT\",\n",
    "    \"PROJECT_RESOURCE_ID\",\n",
    "    \"AZURE_OPENAI_ENDPOINT\",\n",
    "]\n",
    "\n",
    "missing = [v for v in required_vars if not os.environ.get(v)]\n",
    "if missing:\n",
    "    sys.exit(f\"ERROR: Missing environment variables: {', '.join(missing)}. \"\n",
    "             f\"Copy sample.env to .env and fill in your values.\")\n",
    "\n",
    "project_endpoint = os.environ[\"PROJECT_ENDPOINT\"]\n",
    "project_resource_id = os.environ[\"PROJECT_RESOURCE_ID\"]\n",
    "project_connection_name = os.getenv(\"PROJECT_CONNECTION_NAME\", \"earthknowledgeconnection\")\n",
    "agent_model = os.getenv(\"AGENT_MODEL\", \"gpt-4.1-mini\")\n",
    "agent_name = os.getenv(\"AGENT_NAME\", \"earth-knowledge-agent\")\n",
    "endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "credential = DefaultAzureCredential()\n",
    "knowledge_source_name = os.getenv(\"AZURE_SEARCH_KNOWLEDGE_SOURCE_NAME\", \"earth-knowledge-source\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX\", \"earth-at-night\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "base_name = os.getenv(\"AZURE_SEARCH_AGENT_NAME\", \"earth-knowledge-base\")\n",
    "\n",
    "# Parse the resource ID\n",
    "parsed_resource_id = parse_resource_id(project_resource_id)\n",
    "subscription_id = parsed_resource_id['subscription']\n",
    "resource_group = parsed_resource_id['resource_group']\n",
    "account_name = parsed_resource_id['name']\n",
    "project_name = parsed_resource_id['child_name_1']\n",
    "\n",
    "print(\"\u2705 Connections loaded successfully\")\n",
    "print(f\"   Search endpoint : {endpoint}\")\n",
    "print(f\"   Project endpoint: {project_endpoint}\")\n",
    "print(f\"   OpenAI endpoint : {azure_openai_endpoint}\")\n",
    "print(f\"   Agent model     : {agent_model}\")\n",
    "print(f\"   Subscription    : {subscription_id}\")\n",
    "print(f\"   Resource group  : {resource_group}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 \u2014 Create a search index\n",
    "\n",
    "Creates an index with fields for text, embeddings, and semantic search."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AzureOpenAIVectorizer, AzureOpenAIVectorizerParameters,\n",
    "    HnswAlgorithmConfiguration, SearchField, SearchIndex,\n",
    "    SemanticConfiguration, SemanticField, SemanticPrioritizedFields,\n",
    "    SemanticSearch, VectorSearch, VectorSearchProfile\n",
    ")\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True, sortable=True, facetable=True),\n",
    "        SearchField(name=\"page_chunk\", type=\"Edm.String\", filterable=False, sortable=False, facetable=False),\n",
    "        SearchField(\n",
    "            name=\"page_embedding_text_3_large\",\n",
    "            type=\"Collection(Edm.Single)\",\n",
    "            stored=False,\n",
    "            vector_search_dimensions=3072,\n",
    "            vector_search_profile_name=\"hnsw_text_3_large\",\n",
    "        ),\n",
    "        SearchField(name=\"page_number\", type=\"Edm.Int32\", filterable=True, sortable=True, facetable=True),\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"hnsw_text_3_large\",\n",
    "                algorithm_configuration_name=\"alg\",\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "            )\n",
    "        ],\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"alg\")],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                vectorizer_name=\"azure_openai_text_3_large\",\n",
    "                parameters=AzureOpenAIVectorizerParameters(\n",
    "                    resource_url=azure_openai_endpoint,\n",
    "                    deployment_name=azure_openai_embedding_deployment,\n",
    "                    model_name=azure_openai_embedding_model,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic_config\",\n",
    "        configurations=[\n",
    "            SemanticConfiguration(\n",
    "                name=\"semantic_config\",\n",
    "                prioritized_fields=SemanticPrioritizedFields(\n",
    "                    content_fields=[SemanticField(field_name=\"page_chunk\")]\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"\u2705 Index '{index_name}' created or updated successfully\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 \u2014 Upload documents to the index\n",
    "\n",
    "Loads NASA Earth-at-Night data from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import requests\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/Azure-Samples/\"\n",
    "    \"azure-search-sample-data/refs/heads/main/\"\n",
    "    \"nasa-e-book/earth-at-night-json/documents.json\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "documents = response.json()\n",
    "print(f\"   Downloaded {len(documents)} documents\")\n",
    "\n",
    "with SearchIndexingBufferedSender(\n",
    "    endpoint=endpoint, index_name=index_name, credential=credential\n",
    ") as client:\n",
    "    client.upload_documents(documents=documents)\n",
    "\n",
    "print(f\"\u2705 Documents uploaded to index '{index_name}'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 \u2014 Create a knowledge source\n",
    "\n",
    "A reusable reference to the search index."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexFieldReference, SearchIndexKnowledgeSource,\n",
    "    SearchIndexKnowledgeSourceParameters\n",
    ")\n",
    "\n",
    "ks = SearchIndexKnowledgeSource(\n",
    "    name=knowledge_source_name,\n",
    "    description=\"Knowledge source for Earth at night data\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=index_name,\n",
    "        source_data_fields=[\n",
    "            SearchIndexFieldReference(name=\"id\"),\n",
    "            SearchIndexFieldReference(name=\"page_number\"),\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_source(knowledge_source=ks)\n",
    "print(f\"\u2705 Knowledge source '{knowledge_source_name}' created or updated successfully\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 \u2014 Create a knowledge base\n",
    "\n",
    "Orchestrates agentic retrieval and exposes an MCP endpoint."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    KnowledgeBase, KnowledgeRetrievalMinimalReasoningEffort,\n",
    "    KnowledgeRetrievalOutputMode, KnowledgeSourceReference\n",
    ")\n",
    "\n",
    "knowledge_base = KnowledgeBase(\n",
    "    name=base_name,\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(name=knowledge_source_name)\n",
    "    ],\n",
    "    output_mode=KnowledgeRetrievalOutputMode.EXTRACTIVE_DATA,\n",
    "    retrieval_reasoning_effort=KnowledgeRetrievalMinimalReasoningEffort(),\n",
    ")\n",
    "\n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)\n",
    "index_client.create_or_update_knowledge_base(knowledge_base=knowledge_base)\n",
    "\n",
    "mcp_endpoint = f\"{endpoint}/knowledgebases/{base_name}/mcp?api-version=2025-11-01-Preview\"\n",
    "\n",
    "print(f\"\u2705 Knowledge base '{base_name}' created or updated successfully\")\n",
    "print(f\"   MCP endpoint: {mcp_endpoint}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 \u2014 Set up a project client\n",
    "\n",
    "Connects to your Foundry project and lists existing agents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "project_client = AIProjectClient(endpoint=project_endpoint, credential=credential)\n",
    "\n",
    "existing_agents = list(project_client.agents.list())\n",
    "print(f\"\u2705 Connected to project. Found {len(existing_agents)} existing agent(s).\")\n",
    "for a in existing_agents:\n",
    "    print(f\"   - {a.name} (version {a.version})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 \u2014 Create a project connection\n",
    "\n",
    "Creates an MCP connection in Foundry pointing to the knowledge base.\n",
    "\n",
    "> **Common failure point**: If this step returns a 4xx error, verify:\n",
    "> - Your `PROJECT_RESOURCE_ID` is correct.\n",
    "> - You have the **Azure AI Project Manager** role.\n",
    "> - The project's managed identity is enabled."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import requests\n",
    "from azure.identity import get_bearer_token_provider\n",
    "\n",
    "bearer_token_provider = get_bearer_token_provider(\n",
    "    credential, \"https://management.azure.com/.default\"\n",
    ")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token_provider()}\",\n",
    "}\n",
    "\n",
    "connection_url = (\n",
    "    f\"https://management.azure.com{project_resource_id}\"\n",
    "    f\"/connections/{project_connection_name}\"\n",
    "    f\"?api-version=2025-10-01-preview\"\n",
    ")\n",
    "\n",
    "connection_body = {\n",
    "    \"name\": project_connection_name,\n",
    "    \"type\": \"Microsoft.MachineLearningServices/workspaces/connections\",\n",
    "    \"properties\": {\n",
    "        \"authType\": \"ProjectManagedIdentity\",\n",
    "        \"category\": \"RemoteTool\",\n",
    "        \"target\": mcp_endpoint,\n",
    "        \"isSharedToAll\": True,\n",
    "        \"audience\": \"https://search.azure.com/\",\n",
    "        \"metadata\": {\"ApiType\": \"Azure\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "response = requests.put(connection_url, headers=headers, json=connection_body)\n",
    "\n",
    "if not response.ok:\n",
    "    print(f\"\u274c Connection creation failed: {response.status_code}\")\n",
    "    print(f\"   URL: {connection_url}\")\n",
    "    print(f\"   Response: {response.text}\")\n",
    "    print(\"\\n   Troubleshooting:\")\n",
    "    print(\"   - Verify PROJECT_RESOURCE_ID is correct in your .env file\")\n",
    "    print(\"   - Ensure you have 'Azure AI Project Manager' role on the project\")\n",
    "    print(\"   - Check that project managed identity is enabled\")\n",
    "    response.raise_for_status()\n",
    "else:\n",
    "    print(f\"\u2705 Connection '{project_connection_name}' created or updated successfully\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 \u2014 Create an agent with the MCP tool\n",
    "\n",
    "> **Common failure point**: If the agent does not appear in Foundry:\n",
    "> - Verify your model (`AGENT_MODEL`) is actually deployed in Models + Endpoints.\n",
    "> - Ensure you have the **Azure AI User** role on the project.\n",
    "> - Check that your AI Hub has ML resources (Resource Visualizer in Azure Portal)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition, MCPTool\n",
    "\n",
    "instructions = \"\"\"\n",
    "You are a helpful assistant that must use the knowledge base to answer all the questions from user. You must never answer from your own knowledge under any circumstances.\n",
    "Every answer must always provide annotations for using the MCP knowledge base tool and render them as: `\\u3010message_idx:search_idx\\u2020source_name\\u3011`\n",
    "If you cannot find the answer in the provided knowledge base you must respond with \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "mcp_kb_tool = MCPTool(\n",
    "    server_label=\"knowledge-base\",\n",
    "    server_url=mcp_endpoint,\n",
    "    require_approval=\"never\",\n",
    "    allowed_tools=[\"knowledge_base_retrieve\"],\n",
    "    project_connection_id=project_connection_name,\n",
    ")\n",
    "\n",
    "try:\n",
    "    agent = project_client.agents.create_version(\n",
    "        agent_name=agent_name,\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=agent_model,\n",
    "            instructions=instructions,\n",
    "            tools=[mcp_kb_tool],\n",
    "        ),\n",
    "    )\n",
    "    print(f\"\u2705 AI agent '{agent_name}' created successfully\")\n",
    "    print(f\"   Agent name   : {agent.name}\")\n",
    "    print(f\"   Agent version: {agent.version}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Agent creation failed: {e}\")\n",
    "    print(\"\\n   Troubleshooting:\")\n",
    "    print(f\"   - Is '{agent_model}' deployed in your project's Models + Endpoints?\")\n",
    "    print(\"   - Do you have the 'Azure AI User' role on the project?\")\n",
    "    print(\"   - Does your AI Hub have ML resources? (Check Resource Visualizer)\")\n",
    "    raise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate: Confirm the agent exists"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Verify the agent was created\n",
    "agents_after = list(project_client.agents.list())\n",
    "agent_names = [a.name for a in agents_after]\n",
    "\n",
    "if agent_name in agent_names:\n",
    "    print(f\"\u2705 Agent '{agent_name}' confirmed in agent list\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  Agent '{agent_name}' NOT found in agent list.\")\n",
    "    print(f\"   Available agents: {agent_names}\")\n",
    "    print(\"   The chat step below will likely fail.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 \u2014 Chat with the agent\n",
    "\n",
    "Uses the Conversations and Responses APIs to interact with the agent.\n",
    "\n",
    "> **This is the step where BadRequestError 400 typically occurs.**\n",
    "> The error handling below will print the full error details to help diagnose the issue."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get the OpenAI client for responses and conversations\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "try:\n",
    "    conversation = openai_client.conversations.create()\n",
    "    print(f\"   Conversation created: {conversation.id}\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Failed to create conversation: {e}\")\n",
    "    print(\"\\n   This usually means:\")\n",
    "    print(\"   - Your AI Hub is missing ML resources (most common)\")\n",
    "    print(\"   - The project endpoint is incorrect\")\n",
    "    print(\"   - 'Azure AI User' role is not assigned\")\n",
    "    raise\n",
    "\n",
    "# Send the query to the agent\n",
    "try:\n",
    "    response = openai_client.responses.create(\n",
    "        conversation=conversation.id,\n",
    "        tool_choice=\"required\",\n",
    "        input=(\n",
    "            \"Why do suburban belts display larger December brightening \"\n",
    "            \"than urban cores even though absolute light levels are higher downtown? \"\n",
    "            \"Why is the Phoenix nighttime street grid so sharply visible from space, \"\n",
    "            \"whereas large stretches of the interstate between midwestern cities \"\n",
    "            \"remain comparatively dim?\"\n",
    "        ),\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    )\n",
    "    print(f\"\\n\u2705 Response received:\\n\")\n",
    "    print(response.output_text)\n",
    "\n",
    "except Exception as e:\n",
    "    error_msg = str(e)\n",
    "    print(f\"\u274c Chat request failed: {e}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"DIAGNOSTIC INFORMATION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Agent name    : {agent.name}\")\n",
    "    print(f\"Agent version : {agent.version}\")\n",
    "    print(f\"Agent model   : {agent_model}\")\n",
    "    print(f\"MCP endpoint  : {mcp_endpoint}\")\n",
    "    print(f\"Connection    : {project_connection_name}\")\n",
    "    print(f\"Project endpt : {project_endpoint}\")\n",
    "    print()\n",
    "\n",
    "    if \"aml_connections_decode_error\" in error_msg or \"decode AML\" in error_msg:\n",
    "        print(\"\ud83d\udd0d ROOT CAUSE: AML connections decode error\")\n",
    "        print(\"   Your AI Hub is missing Machine Learning resources.\")\n",
    "        print(\"   FIX: Go to Azure Portal \u2192 Resource Group \u2192 Resource Visualizer\")\n",
    "        print(\"   and verify an ML Service exists alongside your AI Hub.\")\n",
    "        print(\"   If missing, recreate the project to provision ML resources.\")\n",
    "    elif \"authentication\" in error_msg.lower() or \"unauthorized\" in error_msg.lower():\n",
    "        print(\"\ud83d\udd0d ROOT CAUSE: Authentication / authorization failure\")\n",
    "        print(\"   FIX: Run 'az login' again and verify all RBAC roles are assigned.\")\n",
    "        print(\"   Especially: 'Azure AI User' and 'Azure AI Project Manager'.\")\n",
    "    elif \"not found\" in error_msg.lower():\n",
    "        print(\"\ud83d\udd0d ROOT CAUSE: Agent or model not found\")\n",
    "        print(f\"   FIX: Verify '{agent_model}' is deployed in Models + Endpoints.\")\n",
    "        print(f\"   Also verify agent '{agent.name}' exists (run validation cell above).\")\n",
    "    else:\n",
    "        print(\"\ud83d\udd0d UNKNOWN ERROR \u2014 Full details above.\")\n",
    "        print(\"   Common fixes:\")\n",
    "        print(\"   1. Ensure AI Hub has ML resources (Resource Visualizer)\")\n",
    "        print(\"   2. Re-run 'az login'\")\n",
    "        print(\"   3. Verify all RBAC roles from README\")\n",
    "        print(\"   4. Ensure Search service is in a supported region\")\n",
    "        print(\"   5. Check that managed identities are enabled on both services\")\n",
    "    raise"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 \u2014 Inspect the response metadata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# View the full response including citations and query metadata\n",
    "try:\n",
    "    response.to_dict()\n",
    "except NameError:\n",
    "    print(\"\u26a0\ufe0f  No response to inspect \u2014 the chat step did not succeed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11 \u2014 Clean up resources (optional)\n",
    "\n",
    "Run this cell to delete all objects created by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u26a0\ufe0f  Uncomment the lines below to delete resources\n",
    "\n",
    "# # Delete the agent\n",
    "# project_client.agents.delete_version(agent.name, agent.version)\n",
    "# print(f\"Deleted agent '{agent.name}' version '{agent.version}'\")\n",
    "\n",
    "# # Delete the knowledge base\n",
    "# index_client.delete_knowledge_base(base_name)\n",
    "# print(f\"Deleted knowledge base '{base_name}'\")\n",
    "\n",
    "# # Delete the knowledge source\n",
    "# index_client.delete_knowledge_source(knowledge_source=knowledge_source_name)\n",
    "# print(f\"Deleted knowledge source '{knowledge_source_name}'\")\n",
    "\n",
    "# # Delete the search index\n",
    "# index_client.delete_index(index)\n",
    "# print(f\"Deleted index '{index_name}'\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}